{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "LSTM_TestV2.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "uoM8pjyHY2Jt",
    "outputId": "654d6ea5-2dd1-40a5-824a-6f34ba1ca8f2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "!pip install tensorflow-gpu"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
      "\u001B[K     |████████████████████████████████| 320.4MB 46kB/s \n",
      "\u001B[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.33.1)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.3.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-2.3.1\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RhXgdKwJY-fQ",
    "outputId": "9f9544b1-8575-438f-bc42-f93beb8f8d5f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "!nvidia-smi"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mon Nov  2 11:32:32 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1GcW8GtEZAbr",
    "outputId": "0ced0795-c23b-46b4-cb31-ae97241c0a64",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xPBFJBZuZkhb"
   },
   "source": [
    "DIR_ROOT = '/content/drive/My Drive/DeepLearning/Data_PhanLoaiBaoLuc'\n",
    "DIR_INPUT_TRAIN = DIR_ROOT + '/InputTrain_30_10_2020_2'\n",
    "DIR_INPUT_TEST = DIR_ROOT + '/Tests/test'\n",
    "DIR_MODEL_LSTM = DIR_ROOT + '/Models/LSTM_Train_30_10_2020_2.h5'\n",
    "DIR_MODEL_CNN = DIR_ROOT + '/Models/VGG16_Model.h5'\n",
    "SIZE = (224, 224)\n",
    "NUM_FRAME_INPUT_LSTM = 20\n",
    "TRANSFER_VALUE_SIZE = 4096\n",
    "RNN_SIZE = 512\n",
    "EPOCH = 300\n",
    "BATCH_SIZE = 150\n",
    "\n",
    "VIDEO_NAMES = [\n",
    "  'da',\n",
    "  'dn',\n",
    "  'nt',\n",
    "  'no'\n",
    "]\n",
    "\n",
    "VIDEO_NAMES_DETAIL = [\n",
    "  'Da',\n",
    "  'Danh, tat',\n",
    "  'Nam toc',\n",
    "  'Binh thuong'\n",
    "]\n",
    "\n",
    "VIDEO_LABELS = [\n",
    "  [1, 0, 0, 0],\n",
    "  [0, 1, 0, 0],\n",
    "  [0, 0, 1, 0],\n",
    "  [0, 0, 0, 1]\n",
    "]\n",
    "\n",
    "NUM_CLASSIFY = len(VIDEO_NAMES)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5X89NBwqgUv4"
   },
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from random import shuffle\n",
    "import numpy as np"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KqfQq2N5ZHL9"
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "def fun_print(name: str, value) -> None:\n",
    "    print('@ Deep Learning> ', name)\n",
    "    print(value)\n",
    "\n",
    "\n",
    "def fun_getFileNames(path: str) -> list:\n",
    "    return os.listdir(path)\n",
    "\n",
    "\n",
    "def fun_showVideoPath(path: str, delay: int = 25) -> None:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    isContinue, frame = cap.read()\n",
    "    while True:\n",
    "        if not isContinue:\n",
    "            break\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(delay=delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "        isContinue, frame = cap.read()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def fun_getFramesOfVideo(path: str, count: int = 20) -> list:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    isContinue, frame = cap.read()\n",
    "    imgs = []\n",
    "    while count > 0:\n",
    "        if not isContinue:\n",
    "            break\n",
    "        imgs.append(frame)\n",
    "        isContinue, frame = cap.read()\n",
    "        count -= 1\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return imgs\n",
    "\n",
    "def fun_getFramesOfVideo_ALL(path: str) -> list:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    isContinue, frame = cap.read()\n",
    "    imgs = []\n",
    "    while True:\n",
    "        if not isContinue:\n",
    "            break\n",
    "        imgs.append(frame)\n",
    "        isContinue, frame = cap.read()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def fun_showVideoFrames(frames: list, delay: int = 25) -> None:\n",
    "    for frame in frames:\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(delay=delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "def fun_showVideo(source, delay: int = 25) -> None:\n",
    "    if isinstance(source, str):\n",
    "        fun_showVideoPath(path=source, delay=delay)\n",
    "    else:\n",
    "        fun_showVideoFrames(frames=source, delay=delay)\n",
    "\n",
    "\n",
    "def fun_resizeFrames(frames: list, size: tuple = (224, 224)) -> list:\n",
    "    imgs = []\n",
    "    count = 0\n",
    "    for frame in frames:\n",
    "        try:\n",
    "          fr = cv2.resize(frame, dsize=size)\n",
    "        except:\n",
    "          print('\\r!Error To Resize of {0}'.format(count))\n",
    "        imgs.append(fr)\n",
    "        count += 1\n",
    "    cv2.destroyAllWindows()\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def fun_saveFramesToVideo(frames: list, path: str, fps: int = 25) -> bool:\n",
    "    try:\n",
    "        height, width, layer = frames[0].shape\n",
    "        wr = cv2.VideoWriter(path, cv2.VideoWriter_fourcc(*'MJPG'), fps, (width, height))\n",
    "        for frame in frames:\n",
    "            wr.write(frame)\n",
    "        wr.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return True\n",
    "\n",
    "    except:\n",
    "        fun_print(name='Write Video: '+path, value='ERROR TO WRITE VIDEO')\n",
    "        return False\n",
    "\n",
    "def fun_getSizeOfFrame(frame) -> tuple:\n",
    "    height, width, layer = frame.shape\n",
    "    return (width, height)\n",
    "\n",
    "# version 1\n",
    "def fun_outListVideoWithNumFrame(pathVideoLoad: str, dirToSave: str, preFixName: str, videoNameIndex: int= None, countFrame: int = 40, fps: int = 25, isShowCalculating: bool = False) -> int:\n",
    "    if videoNameIndex is None:\n",
    "        fun_print('fun_outListVideoWithNumFrame', 'Please input para: videoNameIndex')\n",
    "        return 0\n",
    "\n",
    "    all = 0\n",
    "    countWriten = 0\n",
    "    if isShowCalculating:\n",
    "        fun_print('Calculator Video Out Frame', 'calculating...')\n",
    "        all = fun_getFramesOfVideo_ALL(pathVideoLoad)\n",
    "        all = len(all) // countFrame\n",
    "\n",
    "    cap = cv2.VideoCapture(pathVideoLoad)\n",
    "    isContinue, frame = cap.read()\n",
    "    count = videoNameIndex\n",
    "    while True:\n",
    "        if not isContinue:\n",
    "            break\n",
    "        nameFile = dirToSave + preFixName + '_out_'+str(count)+'.avi'\n",
    "        cFrame = countFrame\n",
    "        frames = []\n",
    "\n",
    "        # get list frame\n",
    "        while cFrame > 0:\n",
    "            frames.append(frame)\n",
    "            isContinue, frame = cap.read()\n",
    "            if not isContinue:\n",
    "                break\n",
    "            cFrame -= 1\n",
    "\n",
    "        # check video enough frameCount frame ?\n",
    "        if len(frames) != countFrame:\n",
    "            break\n",
    "\n",
    "        # write list frame\n",
    "        res = fun_saveFramesToVideo(frames=frames, path=nameFile, fps=fps)\n",
    "        countWriten += 1\n",
    "        if res:\n",
    "            if isShowCalculating:\n",
    "                percent = countWriten / all\n",
    "                mess = '\\r - Writen: {0} -> Complete: {1:.1%}'.format(nameFile, percent)\n",
    "                sys.stdout.write(mess)\n",
    "                sys.stdout.flush()\n",
    "            else:\n",
    "                mess = '\\r - Writen: {0} -> Complete'.format(nameFile)\n",
    "                sys.stdout.write(mess)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        # done\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return count\n",
    "\n",
    "def fun_extractZipFile(pathFileZip: str, pathToSave: str) -> None:\n",
    "    if not os.path.exists(pathToSave):\n",
    "        os.makedirs(pathToSave)\n",
    "    fun_print(name='Extract All ' + pathFileZip, value='Extracting...')\n",
    "    if (pathFileZip.endswith('.zip')):\n",
    "        zipfile.ZipFile(file=pathFileZip, mode='r').extractall(path=pathToSave)\n",
    "        print('Extract Done')\n",
    "    else:\n",
    "        print('Please Input zip file')\n",
    "\n",
    "def fun_print_process(count: int, max: int, mess: str = 'Processing: ') -> None:\n",
    "  process = count / max\n",
    "  mess = '\\r - ' +  mess + ' [{0:.1%}]'.format(process)\n",
    "  sys.stdout.write(mess)\n",
    "  sys.stdout.flush()\n",
    "\n",
    "def getModelLSTM(rnn_size: int = 512, input_shape: tuple = (20, 4096), num_classify: int = 3):\n",
    "  modelLSTM = Sequential()\n",
    "  modelLSTM.add(LSTM(rnn_size, input_shape= input_shape))\n",
    "  modelLSTM.add(Dense(1024))\n",
    "  modelLSTM.add(Activation('relu'))\n",
    "  modelLSTM.add(Dense(50))\n",
    "  modelLSTM.add(Activation('sigmoid'))\n",
    "  modelLSTM.add(Dense(num_classify))\n",
    "  modelLSTM.add(Activation('softmax'))\n",
    "  modelLSTM.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "  return modelLSTM\n",
    "\n",
    "def fun_predict(modelLSTM, transferValue, isPrint: bool= True):\n",
    "    arrPre = []\n",
    "    arrPre.append(transferValue)\n",
    "    Real = modelLSTM.predict(np.array(arrPre))\n",
    "    pre = np.argmax(Real)\n",
    "\n",
    "    if isPrint:\n",
    "      print(Real, pre)\n",
    "      print('\\r')\n",
    "    return pre, Real[0][pre]\n",
    "\n",
    "#version 1\n",
    "def fun_loadVideoPredictPutTextAndSave(modelLSTM, pathLoadVideo, pathSave, videoNameDetail: list, perFameInputLSTM= 20, tranferSize: int = 4096, fps: int= 25):\n",
    "    cap = cv2.VideoCapture(pathLoadVideo)\n",
    "    isContinue, frame = cap.read()\n",
    "\n",
    "    size = fun_getSizeOfFrame(frame= frame)\n",
    "    wr = cv2.VideoWriter(pathSave, cv2.VideoWriter_fourcc(*'MJPG'), fps, size)\n",
    "    countFrame = 0\n",
    "\n",
    "    while True:\n",
    "      if not isContinue:\n",
    "        break\n",
    "      \n",
    "      imgs = []\n",
    "      trans = []\n",
    "      count = perFameInputLSTM\n",
    "\n",
    "      while count > 0:\n",
    "        imgs.append(frame)\n",
    "        trans.append(frame)\n",
    "        isContinue, frame = cap.read()\n",
    "        count -= 1\n",
    "\n",
    "      if len(imgs) != perFameInputLSTM:\n",
    "        break\n",
    "\n",
    "      trans = getTransferValue(trans)\n",
    "\n",
    "      pre, real = fun_predict(modelLSTM= modelLSTM, transferValue= trans)\n",
    "\n",
    "      color=(100, 200, 255)\n",
    "      conv = videoNameDetail[pre]\n",
    "\n",
    "      text = 'Predict: {0} -> Real: [ {1} ]'.format(conv, real)\n",
    "\n",
    "      for ff in imgs:\n",
    "        countFrame += 1\n",
    "        # putText\n",
    "        cv2.putText(img=ff,\n",
    "                    text=text,\n",
    "                    org=(50, 100),\n",
    "                    fontScale=1,\n",
    "                    fontFace=cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                    thickness=1,\n",
    "                    color= color )\n",
    "\n",
    "        cv2.putText(img=ff,\n",
    "                    text='Frame Count: {0}'.format(countFrame),\n",
    "                    org=(50, 150),\n",
    "                    fontScale=1,\n",
    "                    fontFace=cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                    thickness=1,\n",
    "                    color= color )\n",
    "\n",
    "        wr.write(ff)\n",
    "\n",
    "      isContinue, frame = cap.read()\n",
    "\n",
    "    wr.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def fun_mergeVideo(dirInput: str, videoNames: list, pathSave, fps: int= 25):\n",
    "  count = 0\n",
    "  max = len(videoNames)\n",
    "  sizeVideoOut = (int(1280 * 0.7), int(720 * 0.7))\n",
    "  wr = cv2.VideoWriter(pathSave, cv2.VideoWriter_fourcc(*'MJPG'), fps, sizeVideoOut)\n",
    "  for name in videoNames:\n",
    "    frames = fun_getFramesOfVideo_ALL(path= dirInput + name)\n",
    "    frames = fun_resizeFrames(frames= frames, size= sizeVideoOut)\n",
    "    for frame in frames:\n",
    "      wr.write(frame)\n",
    "    fun_print_process(count= count, max= max, mess= 'Merge video processing: ')\n",
    "    count += 1\n",
    "  wr.release()\n",
    "  cv2.destroyAllWindows()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4Jf3DElhbx7B",
    "outputId": "5dbc8448-551f-446c-d0e3-23750210fa8d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "fileNames = fun_getFileNames(path= DIR_INPUT_TEST)\n",
    "fun_print(name= 'Xem thư mục bao nhiêu file?: ' + DIR_INPUT_TEST, value= 'Có: {0} Files'.format(len(fileNames)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "@ Deep Learning>  Xem thư mục bao nhiêu file?: /content/drive/My Drive/DeepLearning/Data_PhanLoaiBaoLuc/Tests/test\n",
      "Có: 4 Files\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LcwMfuXQcH67",
    "outputId": "a306159e-7761-4b35-f190-3cac4d9c92a4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "modelVGG16 = load_model(filepath= DIR_MODEL_CNN, compile= False)\n",
    "modelVGG16.summary()\n",
    "modelLSTM = load_model(filepath= DIR_MODEL_LSTM)\n",
    "modelLSTM.summary()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 512)               9439232   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                51250     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 204       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 10,015,998\n",
      "Trainable params: 10,015,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "huVtzcfldokx"
   },
   "source": [
    "transferLayer = modelVGG16.get_layer(name='fc2')\n",
    "modelVGG16 = Model(inputs= modelVGG16.input, outputs= transferLayer.output)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "78ELX5vVeq9w"
   },
   "source": [
    "def getVideoLabelNames_EachFolder(path: str):\n",
    "  names = []\n",
    "  labels = []\n",
    "  \n",
    "  for fol in VIDEO_NAMES:\n",
    "    folder = path + '/' + fol\n",
    "    fileNames = fun_getFileNames(path= folder)\n",
    "    index = VIDEO_NAMES.index(fol)\n",
    "    for file in fileNames:\n",
    "      names.append('/' + fol + '/' + file)\n",
    "      labels.append(VIDEO_LABELS[index])\n",
    "  \n",
    "  c = list(zip(names, labels))\n",
    "  shuffle(c)\n",
    "\n",
    "  names, labels = zip(*c)\n",
    "  return names, labels"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jbBFFKTmewiZ",
    "outputId": "60b05a38-9075-4ed5-ecae-0ddceb81fa99",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "names, labels = getVideoLabelNames_EachFolder(path= DIR_INPUT_TEST)\n",
    "fun_print('Names', names[0:5])\n",
    "fun_print('labels', labels[0:5])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "@ Deep Learning>  Names\n",
      "('/dn/dn1_113_003.avi', '/no/no_002.avi', '/nt/fi_nt_004.avi', '/nt/fi_nt_001.avi', '/da/da1_111_003.avi')\n",
      "@ Deep Learning>  labels\n",
      "([0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 1, 0], [1, 0, 0, 0])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ES2grrE-fcyY"
   },
   "source": [
    "def getTransferValue(pathVideoOrListFrame):\n",
    "  if isinstance(pathVideoOrListFrame, str):\n",
    "    frames = fun_getFramesOfVideo(path=pathVideoOrListFrame, count=NUM_FRAME_INPUT_LSTM)\n",
    "  else:\n",
    "    frames = pathVideoOrListFrame\n",
    "    \n",
    "  frames = fun_resizeFrames(frames= frames, size=SIZE)\n",
    "\n",
    "  frames = np.array(frames)\n",
    "  frames = (frames / 255.).astype(np.float16)\n",
    "\n",
    "  transfer = modelVGG16.predict(frames)\n",
    "  return transfer"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RnyZyVQ_cVAp",
    "outputId": "3e847411-e14a-430f-957e-47c562c2158f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "transfer = getTransferValue(pathVideoOrListFrame= DIR_INPUT_TEST + '/da/da1_111_001.avi')\n",
    "print(transfer)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[[0.         0.         1.6838499  ... 0.         0.         0.68654674]\n",
      " [0.         0.         1.6627777  ... 0.         0.         0.71237314]\n",
      " [0.         0.         1.6429672  ... 0.         0.         0.67726964]\n",
      " ...\n",
      " [0.         0.         1.5355805  ... 0.         0.         0.84070814]\n",
      " [0.         0.         1.5388265  ... 0.         0.         0.8411636 ]\n",
      " [0.         0.         1.4494164  ... 0.         0.         0.8075534 ]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g_I5dYdsgnXo"
   },
   "source": [
    "def onesHotLabel(label: list):\n",
    "  _ones = np.ones([NUM_FRAME_INPUT_LSTM, NUM_CLASSIFY])\n",
    "  _onesHot = label * _ones\n",
    "  return np.array(_onesHot)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-ft7Mha4gp3a",
    "outputId": "56858e9a-7716-4d5e-a250-9b81ff6bbda2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "_oneHot = onesHotLabel([1, 0, 0, 0])\n",
    "fun_print(name='oneHost', value= _oneHot)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "@ Deep Learning>  oneHost\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "74gcEnYFgwn4",
    "outputId": "ce855456-e96e-4fc9-ccac-223c1d7d3f75",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "names, labels = getVideoLabelNames_EachFolder(path= DIR_INPUT_TEST)\n",
    "\n",
    "fun_print(name= 'Size of List video', value= len(names))\n",
    "fun_print(name= 'Size of List labels', value= len(labels))\n",
    "\n",
    "print('= '*50)\n",
    "\n",
    "print(names[0:5])\n",
    "print(labels[0:5])\n",
    "\n",
    "print('= '*50)\n",
    "\n",
    "print(getTransferValue(DIR_INPUT_TRAIN + names[0]))\n",
    "print(onesHotLabel(labels[0]))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "@ Deep Learning>  Size of List video\n",
      "20\n",
      "@ Deep Learning>  Size of List labels\n",
      "20\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "('/da/da1_113_001.avi', '/nt/fi_nt_005.avi', '/nt/fi_nt_002.avi', '/nt/fi_nt_003.avi', '/no/no_001.avi')\n",
      "([1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0, 0, 0, 1])\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "[[0.         0.         1.6406014  ... 0.         0.         0.6860293 ]\n",
      " [0.         0.         1.671472   ... 0.         0.         0.6824765 ]\n",
      " [0.         0.         1.7053887  ... 0.         0.         0.7028643 ]\n",
      " ...\n",
      " [0.         0.         1.514013   ... 0.         0.         0.92988265]\n",
      " [0.         0.         1.5307286  ... 0.         0.         0.93455213]\n",
      " [0.         0.         1.5738035  ... 0.         0.         0.91121125]]\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4VT10ylMhErz"
   },
   "source": [
    "def getTrainSet_LabelSet(numItem: int):\n",
    "  count = 0\n",
    "  trainSet = []\n",
    "  labelSet = []\n",
    "  while count < numItem:\n",
    "    itemTrain = getTransferValue(pathVideoOrListFrame= DIR_INPUT_TEST + names[count])\n",
    "    itemLable = onesHotLabel(label= labels[count])\n",
    "\n",
    "    trainSet.append(itemTrain)\n",
    "    labelSet.append(itemLable[0])\n",
    "\n",
    "    fun_print_process(count= count, max= numItem, mess= 'Video frame throw into VGG16 Model Processing: ')\n",
    "\n",
    "    count += 1\n",
    "  \n",
    "  return trainSet, labelSet"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HidaFLychSj2",
    "outputId": "1e43d552-223d-4c03-a8c8-5df307f83b69",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "testSet, testLabelSet = getTrainSet_LabelSet(numItem= len(names))\n",
    "fun_print(name= 'Get transfer value', value= 'Finish')\n",
    "print('LEN TRAINT: ', len(testSet))\n",
    "print('NUM FREAMS INPUT: ', len(testSet[0]))\n",
    "print('SIZE TRANSFER: ', len(testSet[0][0]))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      " - Video frame throw into VGG16 Model Processing:  [95.0%]@ Deep Learning>  Get transfer value\n",
      "Finish\n",
      "LEN TRAINT:  20\n",
      "NUM FREAMS INPUT:  20\n",
      "SIZE TRANSFER:  4096\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nX8fiBRshUya",
    "outputId": "005d9e2c-0772-4208-86bb-1f8c72e0a688",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "result = modelLSTM.evaluate(np.array(testSet), np.array(testLabelSet))\n",
    "for name, value in zip(modelLSTM.metrics_names, result):\n",
    "  print(name, value)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9000\n",
      "loss 0.036638252437114716\n",
      "accuracy 0.8999999761581421\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qud1XQ-jltOd",
    "outputId": "fe53742f-419a-4719-b5db-7c7d91bb1239",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "count = 1\n",
    "for name in names:\n",
    "  transfer = getTransferValue(pathVideoOrListFrame= DIR_INPUT_TEST + name)\n",
    "  pre, real = fun_predict(modelLSTM= modelLSTM, transferValue= transfer, isPrint= False)\n",
    "  fun_print(name= 'predict video: ' + str(count)+ name, value= VIDEO_NAMES_DETAIL[pre])\n",
    "  count += 1"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "@ Deep Learning>  predict video: 1/da/da1_113_001.avi\n",
      "Da\n",
      "@ Deep Learning>  predict video: 2/nt/fi_nt_005.avi\n",
      "Nam toc\n",
      "@ Deep Learning>  predict video: 3/nt/fi_nt_002.avi\n",
      "Nam toc\n",
      "@ Deep Learning>  predict video: 4/nt/fi_nt_003.avi\n",
      "Nam toc\n",
      "@ Deep Learning>  predict video: 5/no/no_001.avi\n",
      "Binh thuong\n",
      "@ Deep Learning>  predict video: 6/no/no_003.avi\n",
      "Binh thuong\n",
      "@ Deep Learning>  predict video: 7/no/no_005.avi\n",
      "Binh thuong\n",
      "@ Deep Learning>  predict video: 8/nt/fi_nt_004.avi\n",
      "Nam toc\n",
      "@ Deep Learning>  predict video: 9/no/no_002.avi\n",
      "Binh thuong\n",
      "@ Deep Learning>  predict video: 10/no/no_004.avi\n",
      "Binh thuong\n",
      "@ Deep Learning>  predict video: 11/dn/dn1_112_001.avi\n",
      "Danh, tat\n",
      "@ Deep Learning>  predict video: 12/nt/fi_nt_001.avi\n",
      "Nam toc\n",
      "@ Deep Learning>  predict video: 13/da/da1_111_003.avi\n",
      "Danh, tat\n",
      "@ Deep Learning>  predict video: 14/dn/dn1_113_001.avi\n",
      "Danh, tat\n",
      "@ Deep Learning>  predict video: 15/da/da1_111_002.avi\n",
      "Da\n",
      "@ Deep Learning>  predict video: 16/dn/dn1_112_002.avi\n",
      "Danh, tat\n",
      "@ Deep Learning>  predict video: 17/dn/dn1_113_002.avi\n",
      "Danh, tat\n",
      "@ Deep Learning>  predict video: 18/dn/dn1_113_003.avi\n",
      "Danh, tat\n",
      "@ Deep Learning>  predict video: 19/da/da1_111_004.avi\n",
      "Da\n",
      "@ Deep Learning>  predict video: 20/da/da1_111_001.avi\n",
      "Nam toc\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MMQ8v8GUnpF3",
    "outputId": "8c61d59a-25a1-4a8e-9ce9-49557f730c94",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "fun_loadVideoPredictPutTextAndSave(modelLSTM= modelLSTM, pathLoadVideo= DIR_ROOT + '/Tests/video_test7.mp4', pathSave= DIR_ROOT + '/Tests/video_test7_out_2_11_2020.avi', videoNameDetail= VIDEO_NAMES_DETAIL)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[[0.9924664  0.00121097 0.00208111 0.0042416 ]] 0\n",
      "\n",
      "[[0.9871034  0.00130305 0.00657069 0.00502283]] 0\n",
      "\n",
      "[[2.6706156e-01 5.7396817e-04 6.9782847e-01 3.4536004e-02]] 2\n",
      "\n",
      "[[7.8150797e-01 6.5447146e-04 1.8900414e-01 2.8833453e-02]] 0\n",
      "\n",
      "[[0.991198   0.00149295 0.00229249 0.00501648]] 0\n",
      "\n",
      "[[0.01180492 0.00107616 0.98220223 0.00491679]] 2\n",
      "\n",
      "[[0.01997434 0.00246015 0.9720729  0.00549262]] 2\n",
      "\n",
      "[[0.55067027 0.00243569 0.42927757 0.01761642]] 0\n",
      "\n",
      "[[0.98845834 0.00156837 0.00322536 0.00674795]] 0\n",
      "\n",
      "[[0.6114996  0.00426345 0.0045195  0.37971747]] 0\n",
      "\n",
      "[[0.97916585 0.00236071 0.01271186 0.0057616 ]] 0\n",
      "\n",
      "[[0.954458   0.02236244 0.01171085 0.01146872]] 0\n",
      "\n",
      "[[4.9535930e-03 1.7106038e-04 7.6021630e-01 2.3465903e-01]] 2\n",
      "\n",
      "[[2.7034909e-03 3.1386683e-04 9.9134773e-01 5.6349193e-03]] 2\n",
      "\n",
      "[[1.3381468e-02 2.3069573e-04 9.4545978e-01 4.0928081e-02]] 2\n",
      "\n",
      "[[2.2580829e-02 2.0925669e-04 7.9692495e-01 1.8028501e-01]] 2\n",
      "\n",
      "[[8.3823912e-03 1.4410650e-04 4.2612991e-01 5.6534356e-01]] 3\n",
      "\n",
      "[[9.8159024e-03 2.2470311e-04 9.5434105e-01 3.5618391e-02]] 2\n",
      "\n",
      "[[5.3143962e-03 3.1727896e-04 9.8888493e-01 5.4834196e-03]] 2\n",
      "\n",
      "[[2.3337744e-02 7.3678652e-04 4.4476394e-02 9.3144906e-01]] 3\n",
      "\n",
      "[[0.41691154 0.00072317 0.51104486 0.07132041]] 2\n",
      "\n",
      "[[5.7390598e-03 2.1766764e-04 5.2951969e-02 9.4109136e-01]] 3\n",
      "\n",
      "[[7.983566e-03 9.667755e-05 8.400651e-02 9.079132e-01]] 3\n",
      "\n",
      "[[1.8034637e-02 8.4602638e-05 9.0059228e-02 8.9182150e-01]] 3\n",
      "\n",
      "[[4.5008035e-03 7.2492672e-05 6.1763590e-03 9.8925042e-01]] 3\n",
      "\n",
      "[[0.6091062  0.04745258 0.00372971 0.33971146]] 0\n",
      "\n",
      "[[0.65894014 0.27788937 0.0093288  0.05384168]] 0\n",
      "\n",
      "[[0.30594748 0.01142017 0.00292965 0.67970264]] 3\n",
      "\n",
      "[[0.975159   0.0097667  0.00428944 0.01078496]] 0\n",
      "\n",
      "[[0.9145733  0.03434257 0.00436005 0.04672408]] 0\n",
      "\n",
      "[[0.7778977  0.00824298 0.00232011 0.21153918]] 0\n",
      "\n",
      "!Error To Resize of 13\n",
      "!Error To Resize of 14\n",
      "!Error To Resize of 15\n",
      "!Error To Resize of 16\n",
      "!Error To Resize of 17\n",
      "!Error To Resize of 18\n",
      "!Error To Resize of 19\n",
      "[[0.36168316 0.00420181 0.00146473 0.6326503 ]] 3\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ORv_Vog8sWK2",
    "outputId": "602d0ec9-16e6-4b20-e2a8-6fbd4a77e184",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "videoMerge = fun_mergeVideo(dirInput= DIR_INPUT_TRAIN, videoNames= names, pathSave= DIR_ROOT + '/Tests/videoMerge.avi')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      " - Merge video processing:  [95.0%]"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}