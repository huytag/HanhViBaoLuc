{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ociz_GwpgGiA"
      },
      "source": [
        "Install tensorflow gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTZNdbAXgApw",
        "outputId": "d9367201-3c43-4d12-f036-7dda8bf9fb8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sxcWqfkgpvk",
        "outputId": "3ced4c14-9153-4164-e1ab-f7e5e6553f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Oct 24 04:52:29 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTfNzeF3gs-H",
        "outputId": "12e4b601-bfc6-44c8-a6a7-6eacc3ed0e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-wkYH-ehl6F"
      },
      "source": [
        "Kết nối tới google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHugC54BhuGJ",
        "outputId": "2a5ef666-f091-4fc5-8c59-26d6415757ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4-kzOO6ijpA"
      },
      "source": [
        "Trước khi thực hiện train cần chạy một số modules này trước phục vục cho việc code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r__ZlzkQi4IT"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import zipfile\n",
        "\n",
        "def fun_print(name: str, value) -> None:\n",
        "    print('@ Deep Learning> ', name)\n",
        "    print(value)\n",
        "\n",
        "\n",
        "def fun_getFileNames(path: str) -> list:\n",
        "    return os.listdir(path)\n",
        "\n",
        "\n",
        "def fun_showVideoPath(path: str, delay: int = 25) -> None:\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    isContinue, frame = cap.read()\n",
        "    while True:\n",
        "        if not isContinue:\n",
        "            break\n",
        "        cv2.imshow('frame', frame)\n",
        "        if cv2.waitKey(delay=delay) & 0xFF == ord('q'):\n",
        "            break\n",
        "        isContinue, frame = cap.read()\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "def fun_getFramesOfVideo(path: str, count: int = 20) -> list:\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    isContinue, frame = cap.read()\n",
        "    imgs = []\n",
        "    while count > 0:\n",
        "        if not isContinue:\n",
        "            break\n",
        "        imgs.append(frame)\n",
        "        isContinue, frame = cap.read()\n",
        "        count -= 1\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    return imgs\n",
        "\n",
        "def fun_getFramesOfVideo_ALL(path: str) -> list:\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    isContinue, frame = cap.read()\n",
        "    imgs = []\n",
        "    while True:\n",
        "        if not isContinue:\n",
        "            break\n",
        "        imgs.append(frame)\n",
        "        isContinue, frame = cap.read()\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    return imgs\n",
        "\n",
        "\n",
        "def fun_showVideoFrames(frames: list, delay: int = 25) -> None:\n",
        "    for frame in frames:\n",
        "        cv2.imshow('frame', frame)\n",
        "        if cv2.waitKey(delay=delay) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "\n",
        "def fun_showVideo(source, delay: int = 25) -> None:\n",
        "    if isinstance(source, str):\n",
        "        fun_showVideoPath(path=source, delay=delay)\n",
        "    else:\n",
        "        fun_showVideoFrames(frames=source, delay=delay)\n",
        "\n",
        "\n",
        "def fun_resizeFrames(frames: list, size: tuple = (224, 224)) -> list:\n",
        "    imgs = []\n",
        "    for frame in frames:\n",
        "        try:\n",
        "          fr = cv2.resize(frame, dsize=size)\n",
        "        except:\n",
        "          print('\\r!Error To Resize of {0}'.format(len(frames)))\n",
        "        imgs.append(fr)\n",
        "    cv2.destroyAllWindows()\n",
        "    return imgs\n",
        "\n",
        "\n",
        "def fun_saveFramesToVideo(frames: list, path: str, fps: int = 25) -> bool:\n",
        "    try:\n",
        "        height, width, layer = frames[0].shape\n",
        "        wr = cv2.VideoWriter(path, cv2.VideoWriter_fourcc(*'MJPG'), fps, (width, height))\n",
        "        for frame in frames:\n",
        "            wr.write(frame)\n",
        "        wr.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        return True\n",
        "\n",
        "    except:\n",
        "        fun_print(name='Write Video: '+path, value='ERROR TO WRITE VIDEO')\n",
        "        return False\n",
        "\n",
        "def fun_getSizeOfFrame(frame) -> tuple:\n",
        "    height, width, layer = frame.shape\n",
        "    return (width, height)\n",
        "\n",
        "# version 1\n",
        "def fun_outListVideoWithNumFrame(pathVideoLoad: str, dirToSave: str, preFixName: str, videoNameIndex: int= None, countFrame: int = 40, fps: int = 25, isShowCalculating: bool = False) -> int:\n",
        "    if videoNameIndex is None:\n",
        "        fun_print('fun_outListVideoWithNumFrame', 'Please input para: videoNameIndex')\n",
        "        return 0\n",
        "\n",
        "    all = 0\n",
        "    countWriten = 0\n",
        "    if isShowCalculating:\n",
        "        fun_print('Calculator Video Out Frame', 'calculating...')\n",
        "        all = fun_getFramesOfVideo_ALL(pathVideoLoad)\n",
        "        all = len(all) // countFrame\n",
        "\n",
        "    cap = cv2.VideoCapture(pathVideoLoad)\n",
        "    isContinue, frame = cap.read()\n",
        "    count = videoNameIndex\n",
        "    while True:\n",
        "        if not isContinue:\n",
        "            break\n",
        "        nameFile = dirToSave + preFixName + '_out_'+str(count)+'.avi'\n",
        "        cFrame = countFrame\n",
        "        frames = []\n",
        "\n",
        "        # get list frame\n",
        "        while cFrame > 0:\n",
        "            frames.append(frame)\n",
        "            isContinue, frame = cap.read()\n",
        "            if not isContinue:\n",
        "                break\n",
        "            cFrame -= 1\n",
        "\n",
        "        # check video enough frameCount frame ?\n",
        "        if len(frames) != countFrame:\n",
        "            break\n",
        "\n",
        "        # write list frame\n",
        "        res = fun_saveFramesToVideo(frames=frames, path=nameFile, fps=fps)\n",
        "        countWriten += 1\n",
        "        if res:\n",
        "            if isShowCalculating:\n",
        "                percent = countWriten / all\n",
        "                mess = '\\r - Writen: {0} -> Complete: {1:.1%}'.format(nameFile, percent)\n",
        "                sys.stdout.write(mess)\n",
        "                sys.stdout.flush()\n",
        "            else:\n",
        "                mess = '\\r - Writen: {0} -> Complete'.format(nameFile)\n",
        "                sys.stdout.write(mess)\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        # done\n",
        "        count += 1\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    return count\n",
        "\n",
        "def fun_extractZipFile(pathFileZip: str, pathToSave: str) -> None:\n",
        "    if not os.path.exists(pathToSave):\n",
        "        os.makedirs(pathToSave)\n",
        "    fun_print(name='Extract All ' + pathFileZip, value='Extracting...')\n",
        "    if (pathFileZip.endswith('.zip')):\n",
        "        zipfile.ZipFile(file=pathFileZip, mode='r').extractall(path=pathToSave)\n",
        "        print('Extract Done')\n",
        "    else:\n",
        "        print('Please Input zip file')\n",
        "\n",
        "def fun_print_process(count: int, max: int, mess: str = 'Processing: ') -> None:\n",
        "  process = count / max\n",
        "  mess = '\\r - ' +  mess + ' [{0:.1%}]'.format(process)\n",
        "  sys.stdout.write(mess)\n",
        "  sys.stdout.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GLCrM8PjZFz"
      },
      "source": [
        "Mình cần định nghĩa một số Const để dể dàng thực hiện khi mỗi lần Retrain. TẠI ĐÂY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWhrNy6XjlmX"
      },
      "source": [
        "DIR_ROOT = '/content/drive/My Drive/DeepLearning/Data_PhanLoaiBaoLuc/'\n",
        "DIR_INPUT_TRAIN = DIR_ROOT + 'InputTrainTest/'\n",
        "DIR_MODEL_LSTM = DIR_ROOT + 'Models/LSTM_Train_Viet2.h5'\n",
        "SIZE = (224, 224)\n",
        "NUM_FRAME_INPUT_LSTM = 20\n",
        "NUM_CLASSIFY = 3\n",
        "TRANSFER_VALUE_SIZE = 4096\n",
        "RNN_SIZE = 512\n",
        "EPOCH = 300\n",
        "BATCH_SIZE = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJGGZhxl4usK"
      },
      "source": [
        "Mình cần phải có dữ liệu để train, dữ liệu thường ở dưới máy local, phải tải lên google drive để dùng được cho colab,\n",
        "dữ liệu gồm nhiều files khi tải lên google drive sẽ bất tiện. Mình cần nén nó lại thành file [*.zip] rồi tải lên \n",
        "google drive. Xong sau đó dùng code này để giải nén zip ra thì mình sẽ có dữ liệu,\n",
        "Sau khi mình tải tệp zip lên google drive thì bắt đầu công việc giải nén ra một thư để thực hiện việt input train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q6kApp3jOTa",
        "outputId": "f011f669-52af-41f7-c595-afad63f6be5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "fun_extractZipFile(pathFileZip= DIR_ROOT + 'InputsZip/out3.zip', pathToSave= DIR_INPUT_TRAIN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@ Deep Learning>  Extract All /content/drive/My Drive/DeepLearning/Data_PhanLoaiBaoLuc/InputsZip/out3.zip\n",
            "Extracting...\n",
            "Extract Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKrg2W2Jk3k0"
      },
      "source": [
        "Bây giờ để đảm bảo rằng tất cả các file của chúng ta được giải nén thành công vào trong thư mục mình mong muốn. Mình cần thực hiện dòng lệnh này để xem. Wow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrA52CSzlISt",
        "outputId": "c9c0bd0c-7f8d-47cb-aace-b286066e3db7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "fileNames = fun_getFileNames(path= DIR_INPUT_TRAIN)\n",
        "fun_print(name= 'Xem thư mục bao nhiêu file?: ' + DIR_INPUT_TRAIN, value= 'Có: {0} Files'.format(len(fileNames)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@ Deep Learning>  Xem thư mục bao nhiêu file?: /content/drive/My Drive/DeepLearning/Data_PhanLoaiBaoLuc/InputTrainTest/\n",
            "Có: 15 Files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRNCuJm7lwmb"
      },
      "source": [
        "Wow dữ liệu của mình đã có. Bây giờ bắt đầu giai đoạn tiếp theo. Load model VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFpe8z7y9CJ5"
      },
      "source": [
        "Đầu là khu vực dành cho import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvSJB1L29Iit"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "from keras.models import Model, Sequential, load_model\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "from keras.layers import LSTM, Dense, Activation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rf_jlKT4zeC",
        "outputId": "9e8603aa-03ad-46aa-a582-f896b442af5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "modelCNN = VGG16(include_top= True, weights= 'imagenet')\n",
        "modelCNN.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBfEF8Fg5nWP"
      },
      "source": [
        "Mình sẽ thử dùng modelCNN để predict 20 frame ảnh xem sao."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DTnARS55u57",
        "outputId": "a9829ad2-8a11-4b58-ca40-51e5c99a1b96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "frames = fun_getFramesOfVideo(path= DIR_INPUT_TRAIN + 'fi_da_out_0.avi', count=20)\n",
        "\n",
        "fun_print('count frame: ', value=len(frames))\n",
        "\n",
        "transferLayer = modelCNN.get_layer(name='fc2')\n",
        "\n",
        "imgModelTransfer = Model(inputs= modelCNN.input, outputs= transferLayer.output)\n",
        "\n",
        "frames = fun_resizeFrames(frames= frames, size=SIZE)\n",
        "\n",
        "frames = np.array(frames)\n",
        "frames = (frames / 255.).astype(np.float16)\n",
        "\n",
        "transfer = imgModelTransfer.predict(frames)\n",
        "print(transfer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@ Deep Learning>  count frame: \n",
            "20\n",
            "[[0.         0.         1.2807381  ... 0.         0.         0.9206897 ]\n",
            " [0.         0.         1.2729297  ... 0.         0.         0.9155502 ]\n",
            " [0.         0.         1.2755383  ... 0.         0.         0.9062257 ]\n",
            " ...\n",
            " [0.         0.         1.4305899  ... 0.         0.         0.9416685 ]\n",
            " [0.         0.         1.4025955  ... 0.         0.         0.8959355 ]\n",
            " [0.         0.         1.4778105  ... 0.         0.         0.89356214]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTPtd1xgEOlv"
      },
      "source": [
        "Bây giờ thực thực hiện định nghĩa một hàm. Nhận vào danh sách các video train. Trả về mảng tên video và mảng labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpQbwim8EpZm"
      },
      "source": [
        "def getVideoLabelNames(path: str):\n",
        "  names = []\n",
        "  labels = []\n",
        "  fileNames = fun_getFileNames(path=path)\n",
        "  for file in fileNames:\n",
        "    names.append(file)\n",
        "    if file.find('fi_danh') != -1:\n",
        "      labels.append([1, 0, 0])\n",
        "    elif file.find('fi_da') != -1:\n",
        "      labels.append([0, 1, 0])\n",
        "    elif file.find('fi_nt') != -1:\n",
        "      labels.append([0, 0, 1])\n",
        "  \n",
        "  c = list(zip(names, labels))\n",
        "  shuffle(c)\n",
        "\n",
        "  names, labels = zip(*c)\n",
        "  return names, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N13DBUTGGoEB"
      },
      "source": [
        "Bây giờ test thử hàm getVideoLabelNames(path: str): xem sao"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxG4w-bFGtwd",
        "outputId": "ea55144c-3d56-4c3f-f337-8c7cf3a0f57e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "names, labels = getVideoLabelNames(path= DIR_INPUT_TRAIN)\n",
        "\n",
        "fun_print('Names', names[0:3])\n",
        "fun_print('labels', labels[0:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@ Deep Learning>  Names\n",
            "('fi_danh_out_116.avi', 'fi_nt_out_214.avi', 'fi_danh_out_117.avi')\n",
            "@ Deep Learning>  labels\n",
            "([1, 0, 0], [0, 0, 1], [1, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUrNfDlQLqbx"
      },
      "source": [
        "Bây giờ mình sẽ viết một hàm nhận vào một video. Hàm này sẽ lấy 20 frame hình cho vào VGG16 để lấy mẫu dự đoán"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw3yuc_kL3dk"
      },
      "source": [
        "def getTransferValue(pathVideoOrListFrame):\n",
        "  if isinstance(pathVideoOrListFrame, str):\n",
        "    frames = fun_getFramesOfVideo(path=pathVideoOrListFrame, count=NUM_FRAME_INPUT_LSTM)\n",
        "  else:\n",
        "    frames = pathVideoOrListFrame\n",
        "    \n",
        "  frames = fun_resizeFrames(frames= frames, size=SIZE)\n",
        "\n",
        "  frames = np.array(frames)\n",
        "  frames = (frames / 255.).astype(np.float16)\n",
        "\n",
        "  transfer = imgModelTransfer.predict(frames)\n",
        "  return transfer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyMWw6ewNyh6"
      },
      "source": [
        "Cùng test thử getTransferValue(pathVideo: str): xem nào!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc3OfEEBN3CM",
        "outputId": "a0e8753d-93e6-49b9-b819-f66dd8261ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "transfer = getTransferValue(pathVideoOrListFrame= DIR_INPUT_TRAIN + 'fi_da_out_0.avi')\n",
        "print(transfer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         1.2807381  ... 0.         0.         0.9206897 ]\n",
            " [0.         0.         1.2729297  ... 0.         0.         0.9155502 ]\n",
            " [0.         0.         1.2755383  ... 0.         0.         0.9062257 ]\n",
            " ...\n",
            " [0.         0.         1.4305899  ... 0.         0.         0.9416685 ]\n",
            " [0.         0.         1.4025955  ... 0.         0.         0.8959355 ]\n",
            " [0.         0.         1.4778105  ... 0.         0.         0.89356214]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SdqDS-HOv-_"
      },
      "source": [
        "Wowww. Bây giờ mình sẽ định nghĩa một hàm nhận vào một nhãn của video (label) trả về một dạng ones hot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swW0R-tRP0YR"
      },
      "source": [
        "def onesHotLabel(label: list):\n",
        "  _ones = np.ones([NUM_FRAME_INPUT_LSTM, NUM_CLASSIFY])\n",
        "  _onesHot = label * _ones\n",
        "  return np.array(_onesHot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahzZ6Id1RUYB"
      },
      "source": [
        "Test thử hàm oneHotLabel(label: list): xem nào!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7LNfIMlRfQs",
        "outputId": "98fcc248-ab70-4c6d-e56a-4d6be85cc4b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "_oneHot = onesHotLabel([0, 1, 0])\n",
        "fun_print(name='oneHost', value= _oneHot)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@ Deep Learning>  oneHost\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifJyW9PUSODC"
      },
      "source": [
        "Từ nãy giờ cũng được nhiều rồi. Để đảm bảo rằng dữ liệu hợp lệ. Bạn hãy test lại một lần nửa xem đã có dữ liệu chưa. Hãy thực hiện các lệnh dưới đây."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCLDGBkxSxW7",
        "outputId": "0806d38f-0570-48f4-d97b-3cb624491ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "names, labels = getVideoLabelNames(path= DIR_INPUT_TRAIN)\n",
        "\n",
        "fun_print(name= 'Size of List video', value= len(names))\n",
        "fun_print(name= 'Size of List labels', value= len(labels))\n",
        "\n",
        "print('= '*50)\n",
        "\n",
        "print(names[0:5])\n",
        "print(labels[0:5])\n",
        "\n",
        "print('= '*50)\n",
        "\n",
        "print(getTransferValue(DIR_INPUT_TRAIN + names[0]))\n",
        "print(onesHotLabel(labels[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@ Deep Learning>  Size of List video\n",
            "15\n",
            "@ Deep Learning>  Size of List labels\n",
            "15\n",
            "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
            "('fi_danh_out_115.avi', 'fi_nt_out_215.avi', 'fi_danh_out_116.avi', 'fi_nt_out_216.avi', 'fi_da_out_4.avi')\n",
            "([1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 0])\n",
            "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
            "[[0.         0.         1.2836535  ... 0.         0.         0.80077934]\n",
            " [0.         0.         1.2165948  ... 0.         0.         0.91821134]\n",
            " [0.         0.         1.2474657  ... 0.         0.         0.97603726]\n",
            " ...\n",
            " [0.         0.         1.1223265  ... 0.         0.         0.7579609 ]\n",
            " [0.         0.         1.1686025  ... 0.         0.         0.70442736]\n",
            " [0.         0.         1.2218906  ... 0.         0.         0.7744684 ]]\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttoziX8eaHsA"
      },
      "source": [
        "Nếu mọi thứ đã Ok bây giờ mình sẽ viết một hàm nhận vào số lượng video muốn train. Trả về 2 danh sách:\n",
        "- TranSet: tập dữ liệu train\n",
        "- LabelSet: tập dữ liệu gán nhãn cho mỗi tập trong trainSet.\n",
        "\n",
        "Nếu mọi thứ thuận lợi thì nó là tiền đề để bắt đầu huấn luyện LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADNuptEtaukm"
      },
      "source": [
        "def getTrainSet_LabelSet(numItem: int):\n",
        "  count = 0\n",
        "  trainSet = []\n",
        "  labelSet = []\n",
        "  while count < numItem:\n",
        "    itemTrain = getTransferValue(pathVideoOrListFrame= DIR_INPUT_TRAIN + names[count])\n",
        "    itemLable = onesHotLabel(label= labels[count])\n",
        "\n",
        "    trainSet.append(itemTrain)\n",
        "    labelSet.append(itemLable[0])\n",
        "\n",
        "    fun_print_process(count= count, max= numItem)\n",
        "\n",
        "    count += 1\n",
        "  \n",
        "  return trainSet, labelSet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF_PS6WsdtD4"
      },
      "source": [
        "Cùng Test Thử getTrainSet_LabelSet(numItem: int): xem nào!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTmpsgG3dzBI",
        "outputId": "7967f531-6821-4d8d-b94a-76674c060cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainSet, labelSet = getTrainSet_LabelSet(numItem= len(names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - Processing:  [93.3%]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh5I3f2Vq_ki",
        "outputId": "6201385f-c3f1-4c7d-ea22-6244bf409889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(trainSet))\n",
        "print(len(trainSet[0]))\n",
        "print(len(trainSet[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "750\n",
            "20\n",
            "4096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRYIR16DrFlX",
        "outputId": "87ce55f1-7210-4276-b44a-571dc1ecb196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(labelSet))\n",
        "print(labelSet[0])\n",
        "print(labelSet[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "750\n",
            "[0. 0. 1.]\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUudVjDqmsEK"
      },
      "source": [
        "Hãy viết một hàm trả về cấu trúc model LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB-c0tR-nY-x"
      },
      "source": [
        "def getModelLSTM(rnn_size: int = 512, input_shape: tuple = (20, 4096), num_classify: int = 3):\n",
        "  modelLSTM = Sequential()\n",
        "  modelLSTM.add(LSTM(rnn_size, input_shape= input_shape))\n",
        "  modelLSTM.add(Dense(1024))\n",
        "  modelLSTM.add(Activation('relu'))\n",
        "  modelLSTM.add(Dense(50))\n",
        "  modelLSTM.add(Activation('sigmoid'))\n",
        "  modelLSTM.add(Dense(num_classify))\n",
        "  modelLSTM.add(Activation('softmax'))\n",
        "  modelLSTM.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "  return modelLSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtWiCQHXvA4K",
        "outputId": "aeb6c722-486b-4583-ef0d-2e8299c96085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model = getModelLSTM()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 512)               9439232   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                51250     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 153       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 10,015,947\n",
            "Trainable params: 10,015,947\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmTSgllhibjU",
        "outputId": "1bec85a0-96ac-46b3-ea54-22c41d11f82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(np.array(trainSet), np.array(labelSet), epochs=EPOCH, batch_size=BATCH_SIZE, verbose=2, validation_split= 0.2)\n",
        "\n",
        "model.save(DIR_ROOT + 'Models/LSTM_Train_Viet3.h5')\n",
        "\n",
        "fun_print(name= 'LSTM Train', value= 'Finish')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1/1 - 0s - loss: 0.2266 - accuracy: 0.3333 - val_loss: 0.2679 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/300\n",
            "1/1 - 0s - loss: 0.2442 - accuracy: 0.4167 - val_loss: 0.3818 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/300\n",
            "1/1 - 0s - loss: 0.2370 - accuracy: 0.4167 - val_loss: 0.2781 - val_accuracy: 0.3333\n",
            "Epoch 4/300\n",
            "1/1 - 0s - loss: 0.2321 - accuracy: 0.3333 - val_loss: 0.2306 - val_accuracy: 0.3333\n",
            "Epoch 5/300\n",
            "1/1 - 0s - loss: 0.2152 - accuracy: 0.3333 - val_loss: 0.2287 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/300\n",
            "1/1 - 0s - loss: 0.2112 - accuracy: 0.5833 - val_loss: 0.2683 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/300\n",
            "1/1 - 0s - loss: 0.2063 - accuracy: 0.4167 - val_loss: 0.2898 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/300\n",
            "1/1 - 0s - loss: 0.1999 - accuracy: 0.4167 - val_loss: 0.2623 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/300\n",
            "1/1 - 0s - loss: 0.1867 - accuracy: 0.5000 - val_loss: 0.2418 - val_accuracy: 0.3333\n",
            "Epoch 10/300\n",
            "1/1 - 0s - loss: 0.1788 - accuracy: 0.6667 - val_loss: 0.2596 - val_accuracy: 0.3333\n",
            "Epoch 11/300\n",
            "1/1 - 0s - loss: 0.1680 - accuracy: 0.6667 - val_loss: 0.2541 - val_accuracy: 0.3333\n",
            "Epoch 12/300\n",
            "1/1 - 0s - loss: 0.1611 - accuracy: 0.6667 - val_loss: 0.2607 - val_accuracy: 0.3333\n",
            "Epoch 13/300\n",
            "1/1 - 0s - loss: 0.1432 - accuracy: 0.8333 - val_loss: 0.2446 - val_accuracy: 0.3333\n",
            "Epoch 14/300\n",
            "1/1 - 0s - loss: 0.1395 - accuracy: 0.8333 - val_loss: 0.2606 - val_accuracy: 0.3333\n",
            "Epoch 15/300\n",
            "1/1 - 0s - loss: 0.1278 - accuracy: 0.8333 - val_loss: 0.2476 - val_accuracy: 0.3333\n",
            "Epoch 16/300\n",
            "1/1 - 0s - loss: 0.1217 - accuracy: 0.9167 - val_loss: 0.2332 - val_accuracy: 0.3333\n",
            "Epoch 17/300\n",
            "1/1 - 0s - loss: 0.1137 - accuracy: 0.9167 - val_loss: 0.2446 - val_accuracy: 0.3333\n",
            "Epoch 18/300\n",
            "1/1 - 0s - loss: 0.1076 - accuracy: 0.9167 - val_loss: 0.3057 - val_accuracy: 0.3333\n",
            "Epoch 19/300\n",
            "1/1 - 0s - loss: 0.0920 - accuracy: 0.9167 - val_loss: 0.2575 - val_accuracy: 0.3333\n",
            "Epoch 20/300\n",
            "1/1 - 0s - loss: 0.0842 - accuracy: 0.9167 - val_loss: 0.1987 - val_accuracy: 0.3333\n",
            "Epoch 21/300\n",
            "1/1 - 0s - loss: 0.0826 - accuracy: 0.9167 - val_loss: 0.2220 - val_accuracy: 0.3333\n",
            "Epoch 22/300\n",
            "1/1 - 0s - loss: 0.0686 - accuracy: 0.9167 - val_loss: 0.2883 - val_accuracy: 0.3333\n",
            "Epoch 23/300\n",
            "1/1 - 0s - loss: 0.0638 - accuracy: 0.9167 - val_loss: 0.2586 - val_accuracy: 0.3333\n",
            "Epoch 24/300\n",
            "1/1 - 0s - loss: 0.0617 - accuracy: 0.9167 - val_loss: 0.2492 - val_accuracy: 0.3333\n",
            "Epoch 25/300\n",
            "1/1 - 0s - loss: 0.0571 - accuracy: 0.9167 - val_loss: 0.2715 - val_accuracy: 0.3333\n",
            "Epoch 26/300\n",
            "1/1 - 0s - loss: 0.0506 - accuracy: 0.9167 - val_loss: 0.2856 - val_accuracy: 0.3333\n",
            "Epoch 27/300\n",
            "1/1 - 0s - loss: 0.0443 - accuracy: 0.9167 - val_loss: 0.2981 - val_accuracy: 0.3333\n",
            "Epoch 28/300\n",
            "1/1 - 0s - loss: 0.0395 - accuracy: 0.9167 - val_loss: 0.3006 - val_accuracy: 0.3333\n",
            "Epoch 29/300\n",
            "1/1 - 0s - loss: 0.0332 - accuracy: 0.9167 - val_loss: 0.3011 - val_accuracy: 0.3333\n",
            "Epoch 30/300\n",
            "1/1 - 0s - loss: 0.0281 - accuracy: 0.9167 - val_loss: 0.2925 - val_accuracy: 0.3333\n",
            "Epoch 31/300\n",
            "1/1 - 0s - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.3333\n",
            "Epoch 32/300\n",
            "1/1 - 0s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.3290 - val_accuracy: 0.3333\n",
            "Epoch 33/300\n",
            "1/1 - 0s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.3333\n",
            "Epoch 34/300\n",
            "1/1 - 0s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.3333\n",
            "Epoch 35/300\n",
            "1/1 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.3333\n",
            "Epoch 36/300\n",
            "1/1 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.3333\n",
            "Epoch 37/300\n",
            "1/1 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.3333\n",
            "Epoch 38/300\n",
            "1/1 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3643 - val_accuracy: 0.3333\n",
            "Epoch 39/300\n",
            "1/1 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.3333\n",
            "Epoch 40/300\n",
            "1/1 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.3333\n",
            "Epoch 41/300\n",
            "1/1 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.3333\n",
            "Epoch 42/300\n",
            "1/1 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.3333\n",
            "Epoch 43/300\n",
            "1/1 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.3333\n",
            "Epoch 44/300\n",
            "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.3333\n",
            "Epoch 45/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.3333\n",
            "Epoch 46/300\n",
            "1/1 - 0s - loss: 9.9423e-04 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.3333\n",
            "Epoch 47/300\n",
            "1/1 - 0s - loss: 8.8499e-04 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.3333\n",
            "Epoch 48/300\n",
            "1/1 - 0s - loss: 7.9387e-04 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.3333\n",
            "Epoch 49/300\n",
            "1/1 - 0s - loss: 7.1948e-04 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.3333\n",
            "Epoch 50/300\n",
            "1/1 - 0s - loss: 6.5857e-04 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.3333\n",
            "Epoch 51/300\n",
            "1/1 - 0s - loss: 6.0796e-04 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.3333\n",
            "Epoch 52/300\n",
            "1/1 - 0s - loss: 5.6494e-04 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.3333\n",
            "Epoch 53/300\n",
            "1/1 - 0s - loss: 5.2716e-04 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.3333\n",
            "Epoch 54/300\n",
            "1/1 - 0s - loss: 4.9300e-04 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.3333\n",
            "Epoch 55/300\n",
            "1/1 - 0s - loss: 4.6168e-04 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.3333\n",
            "Epoch 56/300\n",
            "1/1 - 0s - loss: 4.3307e-04 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.3333\n",
            "Epoch 57/300\n",
            "1/1 - 0s - loss: 4.0732e-04 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.3333\n",
            "Epoch 58/300\n",
            "1/1 - 0s - loss: 3.8427e-04 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.3333\n",
            "Epoch 59/300\n",
            "1/1 - 0s - loss: 3.6412e-04 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.3333\n",
            "Epoch 60/300\n",
            "1/1 - 0s - loss: 3.4653e-04 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.3333\n",
            "Epoch 61/300\n",
            "1/1 - 0s - loss: 3.3116e-04 - accuracy: 1.0000 - val_loss: 0.4140 - val_accuracy: 0.3333\n",
            "Epoch 62/300\n",
            "1/1 - 0s - loss: 3.1764e-04 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.3333\n",
            "Epoch 63/300\n",
            "1/1 - 0s - loss: 3.0557e-04 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.3333\n",
            "Epoch 64/300\n",
            "1/1 - 0s - loss: 2.9460e-04 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.3333\n",
            "Epoch 65/300\n",
            "1/1 - 0s - loss: 2.8443e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.3333\n",
            "Epoch 66/300\n",
            "1/1 - 0s - loss: 2.7484e-04 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.3333\n",
            "Epoch 67/300\n",
            "1/1 - 0s - loss: 2.6575e-04 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.3333\n",
            "Epoch 68/300\n",
            "1/1 - 0s - loss: 2.5719e-04 - accuracy: 1.0000 - val_loss: 0.4176 - val_accuracy: 0.3333\n",
            "Epoch 69/300\n",
            "1/1 - 0s - loss: 2.4926e-04 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.3333\n",
            "Epoch 70/300\n",
            "1/1 - 0s - loss: 2.4202e-04 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.3333\n",
            "Epoch 71/300\n",
            "1/1 - 0s - loss: 2.3545e-04 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.3333\n",
            "Epoch 72/300\n",
            "1/1 - 0s - loss: 2.2937e-04 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.3333\n",
            "Epoch 73/300\n",
            "1/1 - 0s - loss: 2.2367e-04 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 0.3333\n",
            "Epoch 74/300\n",
            "1/1 - 0s - loss: 2.1836e-04 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.3333\n",
            "Epoch 75/300\n",
            "1/1 - 0s - loss: 2.1351e-04 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.3333\n",
            "Epoch 76/300\n",
            "1/1 - 0s - loss: 2.0895e-04 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.3333\n",
            "Epoch 77/300\n",
            "1/1 - 0s - loss: 2.0471e-04 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.3333\n",
            "Epoch 78/300\n",
            "1/1 - 0s - loss: 2.0067e-04 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.3333\n",
            "Epoch 79/300\n",
            "1/1 - 0s - loss: 1.9685e-04 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.3333\n",
            "Epoch 80/300\n",
            "1/1 - 0s - loss: 1.9321e-04 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.3333\n",
            "Epoch 81/300\n",
            "1/1 - 0s - loss: 1.8975e-04 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.3333\n",
            "Epoch 82/300\n",
            "1/1 - 0s - loss: 1.8645e-04 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.3333\n",
            "Epoch 83/300\n",
            "1/1 - 0s - loss: 1.8330e-04 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.3333\n",
            "Epoch 84/300\n",
            "1/1 - 0s - loss: 1.8030e-04 - accuracy: 1.0000 - val_loss: 0.4218 - val_accuracy: 0.3333\n",
            "Epoch 85/300\n",
            "1/1 - 0s - loss: 1.7745e-04 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.3333\n",
            "Epoch 86/300\n",
            "1/1 - 0s - loss: 1.7473e-04 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.3333\n",
            "Epoch 87/300\n",
            "1/1 - 0s - loss: 1.7214e-04 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.3333\n",
            "Epoch 88/300\n",
            "1/1 - 0s - loss: 1.6966e-04 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.3333\n",
            "Epoch 89/300\n",
            "1/1 - 0s - loss: 1.6728e-04 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.3333\n",
            "Epoch 90/300\n",
            "1/1 - 0s - loss: 1.6498e-04 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.3333\n",
            "Epoch 91/300\n",
            "1/1 - 0s - loss: 1.6275e-04 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.3333\n",
            "Epoch 92/300\n",
            "1/1 - 0s - loss: 1.6060e-04 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.3333\n",
            "Epoch 93/300\n",
            "1/1 - 0s - loss: 1.5852e-04 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.3333\n",
            "Epoch 94/300\n",
            "1/1 - 0s - loss: 1.5650e-04 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.3333\n",
            "Epoch 95/300\n",
            "1/1 - 0s - loss: 1.5454e-04 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.3333\n",
            "Epoch 96/300\n",
            "1/1 - 0s - loss: 1.5263e-04 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.3333\n",
            "Epoch 97/300\n",
            "1/1 - 0s - loss: 1.5077e-04 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.3333\n",
            "Epoch 98/300\n",
            "1/1 - 0s - loss: 1.4896e-04 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.3333\n",
            "Epoch 99/300\n",
            "1/1 - 0s - loss: 1.4720e-04 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.3333\n",
            "Epoch 100/300\n",
            "1/1 - 0s - loss: 1.4550e-04 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.3333\n",
            "Epoch 101/300\n",
            "1/1 - 0s - loss: 1.4384e-04 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.3333\n",
            "Epoch 102/300\n",
            "1/1 - 0s - loss: 1.4222e-04 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.3333\n",
            "Epoch 103/300\n",
            "1/1 - 0s - loss: 1.4063e-04 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.3333\n",
            "Epoch 104/300\n",
            "1/1 - 0s - loss: 1.3908e-04 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.3333\n",
            "Epoch 105/300\n",
            "1/1 - 0s - loss: 1.3756e-04 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.3333\n",
            "Epoch 106/300\n",
            "1/1 - 0s - loss: 1.3608e-04 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.3333\n",
            "Epoch 107/300\n",
            "1/1 - 0s - loss: 1.3462e-04 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.3333\n",
            "Epoch 108/300\n",
            "1/1 - 0s - loss: 1.3320e-04 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.3333\n",
            "Epoch 109/300\n",
            "1/1 - 0s - loss: 1.3180e-04 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.3333\n",
            "Epoch 110/300\n",
            "1/1 - 0s - loss: 1.3044e-04 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.3333\n",
            "Epoch 111/300\n",
            "1/1 - 0s - loss: 1.2910e-04 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.3333\n",
            "Epoch 112/300\n",
            "1/1 - 0s - loss: 1.2780e-04 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.3333\n",
            "Epoch 113/300\n",
            "1/1 - 0s - loss: 1.2652e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.3333\n",
            "Epoch 114/300\n",
            "1/1 - 0s - loss: 1.2527e-04 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.3333\n",
            "Epoch 115/300\n",
            "1/1 - 0s - loss: 1.2405e-04 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.3333\n",
            "Epoch 116/300\n",
            "1/1 - 0s - loss: 1.2286e-04 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.3333\n",
            "Epoch 117/300\n",
            "1/1 - 0s - loss: 1.2168e-04 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.3333\n",
            "Epoch 118/300\n",
            "1/1 - 0s - loss: 1.2053e-04 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.3333\n",
            "Epoch 119/300\n",
            "1/1 - 0s - loss: 1.1941e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.3333\n",
            "Epoch 120/300\n",
            "1/1 - 0s - loss: 1.1831e-04 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.3333\n",
            "Epoch 121/300\n",
            "1/1 - 0s - loss: 1.1723e-04 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.3333\n",
            "Epoch 122/300\n",
            "1/1 - 0s - loss: 1.1617e-04 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.3333\n",
            "Epoch 123/300\n",
            "1/1 - 0s - loss: 1.1513e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.3333\n",
            "Epoch 124/300\n",
            "1/1 - 0s - loss: 1.1412e-04 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.3333\n",
            "Epoch 125/300\n",
            "1/1 - 0s - loss: 1.1312e-04 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.3333\n",
            "Epoch 126/300\n",
            "1/1 - 0s - loss: 1.1215e-04 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.3333\n",
            "Epoch 127/300\n",
            "1/1 - 0s - loss: 1.1120e-04 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.3333\n",
            "Epoch 128/300\n",
            "1/1 - 0s - loss: 1.1027e-04 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.3333\n",
            "Epoch 129/300\n",
            "1/1 - 0s - loss: 1.0935e-04 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.3333\n",
            "Epoch 130/300\n",
            "1/1 - 0s - loss: 1.0846e-04 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.3333\n",
            "Epoch 131/300\n",
            "1/1 - 0s - loss: 1.0758e-04 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.3333\n",
            "Epoch 132/300\n",
            "1/1 - 0s - loss: 1.0672e-04 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.3333\n",
            "Epoch 133/300\n",
            "1/1 - 0s - loss: 1.0588e-04 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.3333\n",
            "Epoch 134/300\n",
            "1/1 - 0s - loss: 1.0506e-04 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.3333\n",
            "Epoch 135/300\n",
            "1/1 - 0s - loss: 1.0426e-04 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.3333\n",
            "Epoch 136/300\n",
            "1/1 - 0s - loss: 1.0347e-04 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.3333\n",
            "Epoch 137/300\n",
            "1/1 - 0s - loss: 1.0269e-04 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.3333\n",
            "Epoch 138/300\n",
            "1/1 - 0s - loss: 1.0194e-04 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.3333\n",
            "Epoch 139/300\n",
            "1/1 - 0s - loss: 1.0120e-04 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.3333\n",
            "Epoch 140/300\n",
            "1/1 - 0s - loss: 1.0047e-04 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.3333\n",
            "Epoch 141/300\n",
            "1/1 - 0s - loss: 9.9763e-05 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.3333\n",
            "Epoch 142/300\n",
            "1/1 - 0s - loss: 9.9068e-05 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.3333\n",
            "Epoch 143/300\n",
            "1/1 - 0s - loss: 9.8386e-05 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.3333\n",
            "Epoch 144/300\n",
            "1/1 - 0s - loss: 9.7718e-05 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.3333\n",
            "Epoch 145/300\n",
            "1/1 - 0s - loss: 9.7063e-05 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.3333\n",
            "Epoch 146/300\n",
            "1/1 - 0s - loss: 9.6421e-05 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.3333\n",
            "Epoch 147/300\n",
            "1/1 - 0s - loss: 9.5792e-05 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.3333\n",
            "Epoch 148/300\n",
            "1/1 - 0s - loss: 9.5175e-05 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.3333\n",
            "Epoch 149/300\n",
            "1/1 - 0s - loss: 9.4572e-05 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.3333\n",
            "Epoch 150/300\n",
            "1/1 - 0s - loss: 9.3979e-05 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.3333\n",
            "Epoch 151/300\n",
            "1/1 - 0s - loss: 9.3398e-05 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.3333\n",
            "Epoch 152/300\n",
            "1/1 - 0s - loss: 9.2828e-05 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.3333\n",
            "Epoch 153/300\n",
            "1/1 - 0s - loss: 9.2269e-05 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.3333\n",
            "Epoch 154/300\n",
            "1/1 - 0s - loss: 9.1721e-05 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.3333\n",
            "Epoch 155/300\n",
            "1/1 - 0s - loss: 9.1183e-05 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.3333\n",
            "Epoch 156/300\n",
            "1/1 - 0s - loss: 9.0655e-05 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.3333\n",
            "Epoch 157/300\n",
            "1/1 - 0s - loss: 9.0137e-05 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.3333\n",
            "Epoch 158/300\n",
            "1/1 - 0s - loss: 8.9628e-05 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.3333\n",
            "Epoch 159/300\n",
            "1/1 - 0s - loss: 8.9129e-05 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.3333\n",
            "Epoch 160/300\n",
            "1/1 - 0s - loss: 8.8639e-05 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.3333\n",
            "Epoch 161/300\n",
            "1/1 - 0s - loss: 8.8159e-05 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.3333\n",
            "Epoch 162/300\n",
            "1/1 - 0s - loss: 8.7686e-05 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.3333\n",
            "Epoch 163/300\n",
            "1/1 - 0s - loss: 8.7221e-05 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.3333\n",
            "Epoch 164/300\n",
            "1/1 - 0s - loss: 8.6764e-05 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.3333\n",
            "Epoch 165/300\n",
            "1/1 - 0s - loss: 8.6313e-05 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.3333\n",
            "Epoch 166/300\n",
            "1/1 - 0s - loss: 8.5868e-05 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.3333\n",
            "Epoch 167/300\n",
            "1/1 - 0s - loss: 8.5431e-05 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.3333\n",
            "Epoch 168/300\n",
            "1/1 - 0s - loss: 8.5001e-05 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.3333\n",
            "Epoch 169/300\n",
            "1/1 - 0s - loss: 8.4577e-05 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.3333\n",
            "Epoch 170/300\n",
            "1/1 - 0s - loss: 8.4159e-05 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.3333\n",
            "Epoch 171/300\n",
            "1/1 - 0s - loss: 8.3747e-05 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.3333\n",
            "Epoch 172/300\n",
            "1/1 - 0s - loss: 8.3341e-05 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.3333\n",
            "Epoch 173/300\n",
            "1/1 - 0s - loss: 8.2942e-05 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.3333\n",
            "Epoch 174/300\n",
            "1/1 - 0s - loss: 8.2547e-05 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.3333\n",
            "Epoch 175/300\n",
            "1/1 - 0s - loss: 8.2156e-05 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.3333\n",
            "Epoch 176/300\n",
            "1/1 - 0s - loss: 8.1770e-05 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.3333\n",
            "Epoch 177/300\n",
            "1/1 - 0s - loss: 8.1389e-05 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.3333\n",
            "Epoch 178/300\n",
            "1/1 - 0s - loss: 8.1011e-05 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.3333\n",
            "Epoch 179/300\n",
            "1/1 - 0s - loss: 8.0638e-05 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.3333\n",
            "Epoch 180/300\n",
            "1/1 - 0s - loss: 8.0268e-05 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.3333\n",
            "Epoch 181/300\n",
            "1/1 - 0s - loss: 7.9903e-05 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.3333\n",
            "Epoch 182/300\n",
            "1/1 - 0s - loss: 7.9541e-05 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.3333\n",
            "Epoch 183/300\n",
            "1/1 - 0s - loss: 7.9184e-05 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.3333\n",
            "Epoch 184/300\n",
            "1/1 - 0s - loss: 7.8831e-05 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.3333\n",
            "Epoch 185/300\n",
            "1/1 - 0s - loss: 7.8481e-05 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.3333\n",
            "Epoch 186/300\n",
            "1/1 - 0s - loss: 7.8136e-05 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.3333\n",
            "Epoch 187/300\n",
            "1/1 - 0s - loss: 7.7795e-05 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.3333\n",
            "Epoch 188/300\n",
            "1/1 - 0s - loss: 7.7457e-05 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.3333\n",
            "Epoch 189/300\n",
            "1/1 - 0s - loss: 7.7123e-05 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.3333\n",
            "Epoch 190/300\n",
            "1/1 - 0s - loss: 7.6792e-05 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.3333\n",
            "Epoch 191/300\n",
            "1/1 - 0s - loss: 7.6465e-05 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.3333\n",
            "Epoch 192/300\n",
            "1/1 - 0s - loss: 7.6140e-05 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.3333\n",
            "Epoch 193/300\n",
            "1/1 - 0s - loss: 7.5820e-05 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.3333\n",
            "Epoch 194/300\n",
            "1/1 - 0s - loss: 7.5503e-05 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.3333\n",
            "Epoch 195/300\n",
            "1/1 - 0s - loss: 7.5189e-05 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.3333\n",
            "Epoch 196/300\n",
            "1/1 - 0s - loss: 7.4878e-05 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.3333\n",
            "Epoch 197/300\n",
            "1/1 - 0s - loss: 7.4571e-05 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.3333\n",
            "Epoch 198/300\n",
            "1/1 - 0s - loss: 7.4266e-05 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.3333\n",
            "Epoch 199/300\n",
            "1/1 - 0s - loss: 7.3965e-05 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.3333\n",
            "Epoch 200/300\n",
            "1/1 - 0s - loss: 7.3667e-05 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.3333\n",
            "Epoch 201/300\n",
            "1/1 - 0s - loss: 7.3372e-05 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.3333\n",
            "Epoch 202/300\n",
            "1/1 - 0s - loss: 7.3080e-05 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.3333\n",
            "Epoch 203/300\n",
            "1/1 - 0s - loss: 7.2791e-05 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.3333\n",
            "Epoch 204/300\n",
            "1/1 - 0s - loss: 7.2505e-05 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.3333\n",
            "Epoch 205/300\n",
            "1/1 - 0s - loss: 7.2221e-05 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.3333\n",
            "Epoch 206/300\n",
            "1/1 - 0s - loss: 7.1941e-05 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.3333\n",
            "Epoch 207/300\n",
            "1/1 - 0s - loss: 7.1663e-05 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.3333\n",
            "Epoch 208/300\n",
            "1/1 - 0s - loss: 7.1389e-05 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.3333\n",
            "Epoch 209/300\n",
            "1/1 - 0s - loss: 7.1117e-05 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.3333\n",
            "Epoch 210/300\n",
            "1/1 - 0s - loss: 7.0849e-05 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.3333\n",
            "Epoch 211/300\n",
            "1/1 - 0s - loss: 7.0583e-05 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.3333\n",
            "Epoch 212/300\n",
            "1/1 - 0s - loss: 7.0320e-05 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.3333\n",
            "Epoch 213/300\n",
            "1/1 - 0s - loss: 7.0059e-05 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.3333\n",
            "Epoch 214/300\n",
            "1/1 - 0s - loss: 6.9802e-05 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.3333\n",
            "Epoch 215/300\n",
            "1/1 - 0s - loss: 6.9547e-05 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.3333\n",
            "Epoch 216/300\n",
            "1/1 - 0s - loss: 6.9294e-05 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.3333\n",
            "Epoch 217/300\n",
            "1/1 - 0s - loss: 6.9045e-05 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.3333\n",
            "Epoch 218/300\n",
            "1/1 - 0s - loss: 6.8798e-05 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.3333\n",
            "Epoch 219/300\n",
            "1/1 - 0s - loss: 6.8554e-05 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.3333\n",
            "Epoch 220/300\n",
            "1/1 - 0s - loss: 6.8312e-05 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.3333\n",
            "Epoch 221/300\n",
            "1/1 - 0s - loss: 6.8073e-05 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.3333\n",
            "Epoch 222/300\n",
            "1/1 - 0s - loss: 6.7836e-05 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.3333\n",
            "Epoch 223/300\n",
            "1/1 - 0s - loss: 6.7602e-05 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.3333\n",
            "Epoch 224/300\n",
            "1/1 - 0s - loss: 6.7370e-05 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.3333\n",
            "Epoch 225/300\n",
            "1/1 - 0s - loss: 6.7141e-05 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.3333\n",
            "Epoch 226/300\n",
            "1/1 - 0s - loss: 6.6914e-05 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.3333\n",
            "Epoch 227/300\n",
            "1/1 - 0s - loss: 6.6689e-05 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.3333\n",
            "Epoch 228/300\n",
            "1/1 - 0s - loss: 6.6466e-05 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.3333\n",
            "Epoch 229/300\n",
            "1/1 - 0s - loss: 6.6246e-05 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.3333\n",
            "Epoch 230/300\n",
            "1/1 - 0s - loss: 6.6028e-05 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.3333\n",
            "Epoch 231/300\n",
            "1/1 - 0s - loss: 6.5813e-05 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.3333\n",
            "Epoch 232/300\n",
            "1/1 - 0s - loss: 6.5599e-05 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.3333\n",
            "Epoch 233/300\n",
            "1/1 - 0s - loss: 6.5388e-05 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.3333\n",
            "Epoch 234/300\n",
            "1/1 - 0s - loss: 6.5179e-05 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.3333\n",
            "Epoch 235/300\n",
            "1/1 - 0s - loss: 6.4972e-05 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.3333\n",
            "Epoch 236/300\n",
            "1/1 - 0s - loss: 6.4767e-05 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.3333\n",
            "Epoch 237/300\n",
            "1/1 - 0s - loss: 6.4564e-05 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.3333\n",
            "Epoch 238/300\n",
            "1/1 - 0s - loss: 6.4363e-05 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.3333\n",
            "Epoch 239/300\n",
            "1/1 - 0s - loss: 6.4164e-05 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.3333\n",
            "Epoch 240/300\n",
            "1/1 - 0s - loss: 6.3966e-05 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.3333\n",
            "Epoch 241/300\n",
            "1/1 - 0s - loss: 6.3771e-05 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.3333\n",
            "Epoch 242/300\n",
            "1/1 - 0s - loss: 6.3578e-05 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.3333\n",
            "Epoch 243/300\n",
            "1/1 - 0s - loss: 6.3387e-05 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.3333\n",
            "Epoch 244/300\n",
            "1/1 - 0s - loss: 6.3198e-05 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.3333\n",
            "Epoch 245/300\n",
            "1/1 - 0s - loss: 6.3011e-05 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.3333\n",
            "Epoch 246/300\n",
            "1/1 - 0s - loss: 6.2825e-05 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.3333\n",
            "Epoch 247/300\n",
            "1/1 - 0s - loss: 6.2641e-05 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.3333\n",
            "Epoch 248/300\n",
            "1/1 - 0s - loss: 6.2459e-05 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.3333\n",
            "Epoch 249/300\n",
            "1/1 - 0s - loss: 6.2279e-05 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.3333\n",
            "Epoch 250/300\n",
            "1/1 - 0s - loss: 6.2100e-05 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.3333\n",
            "Epoch 251/300\n",
            "1/1 - 0s - loss: 6.1922e-05 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.3333\n",
            "Epoch 252/300\n",
            "1/1 - 0s - loss: 6.1746e-05 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.3333\n",
            "Epoch 253/300\n",
            "1/1 - 0s - loss: 6.1571e-05 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.3333\n",
            "Epoch 254/300\n",
            "1/1 - 0s - loss: 6.1398e-05 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.3333\n",
            "Epoch 255/300\n",
            "1/1 - 0s - loss: 6.1228e-05 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.3333\n",
            "Epoch 256/300\n",
            "1/1 - 0s - loss: 6.1057e-05 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.3333\n",
            "Epoch 257/300\n",
            "1/1 - 0s - loss: 6.0887e-05 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.3333\n",
            "Epoch 258/300\n",
            "1/1 - 0s - loss: 6.0721e-05 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.3333\n",
            "Epoch 259/300\n",
            "1/1 - 0s - loss: 6.0555e-05 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.3333\n",
            "Epoch 260/300\n",
            "1/1 - 0s - loss: 6.0390e-05 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.3333\n",
            "Epoch 261/300\n",
            "1/1 - 0s - loss: 6.0226e-05 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.3333\n",
            "Epoch 262/300\n",
            "1/1 - 0s - loss: 6.0064e-05 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.3333\n",
            "Epoch 263/300\n",
            "1/1 - 0s - loss: 5.9902e-05 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.3333\n",
            "Epoch 264/300\n",
            "1/1 - 0s - loss: 5.9742e-05 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.3333\n",
            "Epoch 265/300\n",
            "1/1 - 0s - loss: 5.9584e-05 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.3333\n",
            "Epoch 266/300\n",
            "1/1 - 0s - loss: 5.9426e-05 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.3333\n",
            "Epoch 267/300\n",
            "1/1 - 0s - loss: 5.9270e-05 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.3333\n",
            "Epoch 268/300\n",
            "1/1 - 0s - loss: 5.9115e-05 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.3333\n",
            "Epoch 269/300\n",
            "1/1 - 0s - loss: 5.8962e-05 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.3333\n",
            "Epoch 270/300\n",
            "1/1 - 0s - loss: 5.8810e-05 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.3333\n",
            "Epoch 271/300\n",
            "1/1 - 0s - loss: 5.8659e-05 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.3333\n",
            "Epoch 272/300\n",
            "1/1 - 0s - loss: 5.8509e-05 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.3333\n",
            "Epoch 273/300\n",
            "1/1 - 0s - loss: 5.8361e-05 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.3333\n",
            "Epoch 274/300\n",
            "1/1 - 0s - loss: 5.8214e-05 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.3333\n",
            "Epoch 275/300\n",
            "1/1 - 0s - loss: 5.8068e-05 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.3333\n",
            "Epoch 276/300\n",
            "1/1 - 0s - loss: 5.7922e-05 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.3333\n",
            "Epoch 277/300\n",
            "1/1 - 0s - loss: 5.7779e-05 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.3333\n",
            "Epoch 278/300\n",
            "1/1 - 0s - loss: 5.7636e-05 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.3333\n",
            "Epoch 279/300\n",
            "1/1 - 0s - loss: 5.7495e-05 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.3333\n",
            "Epoch 280/300\n",
            "1/1 - 0s - loss: 5.7354e-05 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.3333\n",
            "Epoch 281/300\n",
            "1/1 - 0s - loss: 5.7215e-05 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.3333\n",
            "Epoch 282/300\n",
            "1/1 - 0s - loss: 5.7077e-05 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.3333\n",
            "Epoch 283/300\n",
            "1/1 - 0s - loss: 5.6940e-05 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.3333\n",
            "Epoch 284/300\n",
            "1/1 - 0s - loss: 5.6804e-05 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.3333\n",
            "Epoch 285/300\n",
            "1/1 - 0s - loss: 5.6668e-05 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.3333\n",
            "Epoch 286/300\n",
            "1/1 - 0s - loss: 5.6534e-05 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.3333\n",
            "Epoch 287/300\n",
            "1/1 - 0s - loss: 5.6401e-05 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.3333\n",
            "Epoch 288/300\n",
            "1/1 - 0s - loss: 5.6269e-05 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.3333\n",
            "Epoch 289/300\n",
            "1/1 - 0s - loss: 5.6137e-05 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.3333\n",
            "Epoch 290/300\n",
            "1/1 - 0s - loss: 5.6007e-05 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.3333\n",
            "Epoch 291/300\n",
            "1/1 - 0s - loss: 5.5878e-05 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.3333\n",
            "Epoch 292/300\n",
            "1/1 - 0s - loss: 5.5749e-05 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.3333\n",
            "Epoch 293/300\n",
            "1/1 - 0s - loss: 5.5622e-05 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.3333\n",
            "Epoch 294/300\n",
            "1/1 - 0s - loss: 5.5495e-05 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.3333\n",
            "Epoch 295/300\n",
            "1/1 - 0s - loss: 5.5369e-05 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.3333\n",
            "Epoch 296/300\n",
            "1/1 - 0s - loss: 5.5244e-05 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.3333\n",
            "Epoch 297/300\n",
            "1/1 - 0s - loss: 5.5120e-05 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.3333\n",
            "Epoch 298/300\n",
            "1/1 - 0s - loss: 5.4997e-05 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.3333\n",
            "Epoch 299/300\n",
            "1/1 - 0s - loss: 5.4875e-05 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.3333\n",
            "Epoch 300/300\n",
            "1/1 - 0s - loss: 5.4753e-05 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.3333\n",
            "@ Deep Learning>  LSTM Train\n",
            "Finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKVVaPWw_iqH"
      },
      "source": [
        "Wow. Bây giờ hãy cùng test xem độ chính xác của model nào."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFXjHyOU_53d",
        "outputId": "ee39c512-c704-4440-de63-f1024b4e7b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "namesVald, labelsVald = getVideoLabelNames(path= DIR_ROOT + 'InputTrainTest/')\n",
        "\n",
        "print(len(namesVald))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-otwz7wBhVP"
      },
      "source": [
        "def getValdSet_ValdLabelSet(numItem: int):\n",
        "  count = 0\n",
        "  valdSet = []\n",
        "  valdLabel = []\n",
        "  while count < numItem:\n",
        "    itemVald = getTransferValue(pathVideoOrListFrame= DIR_INPUT_TRAIN + namesVald[count])\n",
        "    itemLabel = onesHotLabel(label= labelsVald[count])\n",
        "\n",
        "    valdSet.append(itemVald)\n",
        "    valdLabel.append(itemLabel[0])\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  return valdSet, valdLabel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgHWRjElCwax"
      },
      "source": [
        "valdSet, valdLabelSet = getValdSet_ValdLabelSet(numItem= len(namesVald))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4_RaFFyDGqO",
        "outputId": "6279f067-3f0f-4e6f-d37d-abc442527981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = model.evaluate(np.array(valdSet), np.array(valdLabelSet))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zmjAiHHDcXQ",
        "outputId": "2df2523d-3157-40f2-e335-974e821241dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for name, value in zip(model.metrics_names, result):\n",
        "  print(name, value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 0.17530281841754913\n",
            "accuracy 0.7333333492279053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNxZ0El7EBa1"
      },
      "source": [
        "Woww. Hãy cùng thử predict với từng video và xem kết quả nào"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24b_2KDPEHFg",
        "outputId": "f3d0d6da-fee7-46b6-9ed7-d2746bb5f82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "for file in namesVald:\n",
        "  frames = getTransferValue(pathVideoOrListFrame= DIR_INPUT_TRAIN + file)\n",
        "  pre = model.predict(np.array([frames]))\n",
        "  fun_rint(name= 'predict: ' + file + ' | {0}'.format(np.argmax(pre)), value= pre)\n",
        "  print('\\r')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@ Deep Learning>  predict: fi_nt_out_215.avi | 2\n",
            "[[0.0367764  0.05087447 0.91234916]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_danh_out_117.avi | 0\n",
            "[[0.9572867  0.00143663 0.04127667]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_danh_out_116.avi | 0\n",
            "[[0.9916529  0.00099888 0.00734821]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_da_out_3.avi | 1\n",
            "[[0.00610643 0.87416935 0.11972412]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_nt_out_216.avi | 2\n",
            "[[0.00543498 0.00628432 0.9882808 ]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_danh_out_119.avi | 0\n",
            "[[0.9780797  0.0012411  0.02067921]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_nt_out_213.avi | 2\n",
            "[[0.00474691 0.03336468 0.96188843]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_danh_out_115.avi | 0\n",
            "[[0.99157286 0.00244107 0.0059861 ]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_da_out_2.avi | 2\n",
            "[[0.01611722 0.05550494 0.92837787]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_nt_out_214.avi | 2\n",
            "[[0.00409361 0.01832251 0.9775839 ]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_danh_out_118.avi | 2\n",
            "[[0.09483974 0.00731582 0.89784443]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_da_out_0.avi | 1\n",
            "[[0.00486733 0.98700166 0.00813103]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_da_out_1.avi | 1\n",
            "[[0.00540552 0.986296   0.00829846]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_da_out_4.avi | 1\n",
            "[[0.01446935 0.92071456 0.06481606]]\n",
            "\n",
            "@ Deep Learning>  predict: fi_nt_out_212.avi | 2\n",
            "[[0.00667064 0.02528346 0.96804595]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iww7NJOmI8rX"
      },
      "source": [
        "Bây giờ hãy thử put text và save video về thử xem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by7qvufrJDid"
      },
      "source": [
        "def fun_predict(model, tranfer_value):\n",
        "    arrPre = []\n",
        "    arrPre.append(tranfer_value)\n",
        "    Real = model.predict(np.array(arrPre))\n",
        "    pre = np.argmax(Real)\n",
        "\n",
        "    print(Real, pre)\n",
        "    print('\\r')\n",
        "    return pre, Real[0][pre]\n",
        "\n",
        "#version 1\n",
        "def fun_loadVideoPredictPutTextAndSave(modelCNN, modelLSTM, pathLoadVideo, pathSave, perFameInputLSTM= 20, tranferSize: int = 4096):\n",
        "    if pathLoadVideo is None or pathSave is None or perFameInputLSTM is None or modelCNN is None:\n",
        "        return\n",
        "\n",
        "    cap = cv2.VideoCapture(pathLoadVideo)\n",
        "    isContinue, frame = cap.read()\n",
        "\n",
        "    size = fun_getSizeOfFrame(frame= frame)\n",
        "    wr = cv2.VideoWriter(pathSave, cv2.VideoWriter_fourcc(*'MJPG'), 25, size)\n",
        "    countFrame = 0\n",
        "\n",
        "    while True:\n",
        "      if not isContinue:\n",
        "        break\n",
        "      \n",
        "      imgs = []\n",
        "      trans = []\n",
        "      count = perFameInputLSTM\n",
        "\n",
        "      while count > 0:\n",
        "        imgs.append(frame)\n",
        "        trans.append(frame)\n",
        "        isContinue, frame = cap.read()\n",
        "        count -= 1\n",
        "\n",
        "      trans = getTransferValue(trans)\n",
        "\n",
        "      pre, real = fun_predict(model= model, tranfer_value= trans)\n",
        "\n",
        "      color=(100, 200, 255)\n",
        "      conv = ''\n",
        "      if pre == 0:\n",
        "        conv = 'Danh'\n",
        "        color = (150, 250, 255)\n",
        "      elif pre == 1:\n",
        "        color = (200, 100, 255)\n",
        "        conv = 'Da'\n",
        "      elif pre == 2:\n",
        "        conv = 'Nam Toc'\n",
        "\n",
        "      text = 'Predict: {0} -> Real: [ {1} ]'.format(conv, real)\n",
        "\n",
        "      for ff in imgs:\n",
        "        countFrame += 1\n",
        "        # putText\n",
        "        cv2.putText(img=ff,\n",
        "                    text=text,\n",
        "                    org=(50, 100),\n",
        "                    fontScale=1,\n",
        "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    thickness=2,\n",
        "                    color= color )\n",
        "\n",
        "        cv2.putText(img=ff,\n",
        "                    text='Frame Count: {0}'.format(countFrame),\n",
        "                    org=(50, 150),\n",
        "                    fontScale=1,\n",
        "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    thickness=2,\n",
        "                    color= color )\n",
        "\n",
        "        wr.write(ff)\n",
        "\n",
        "      isContinue, frame = cap.read()\n",
        "\n",
        "    wr.release()\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyGixYdc3JV1",
        "outputId": "35662707-582c-4b98-ab0b-4403bcb919a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model = load_model(DIR_MODEL_LSTM)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_21 (LSTM)               (None, 512)               9439232   \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "activation_57 (Activation)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 50)                51250     \n",
            "_________________________________________________________________\n",
            "activation_58 (Activation)   (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 3)                 153       \n",
            "_________________________________________________________________\n",
            "activation_59 (Activation)   (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 10,015,947\n",
            "Trainable params: 10,015,947\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrYL_eYBMUcq",
        "outputId": "ed9529c1-86f6-4ae5-f98e-e64f83eca600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "fun_loadVideoPredictPutTextAndSave(modelCNN= imgModelTransfer, modelLSTM= model, pathLoadVideo= DIR_ROOT + 'Tests/video_test8.mp4',\n",
        "                                   pathSave= DIR_ROOT + 'Tests/video_test8_out.avi', perFameInputLSTM= 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.9679810e-01 2.3827578e-03 8.1917184e-04]] 0\n",
            "\n",
            "[[0.9936528  0.00311101 0.00323608]] 0\n",
            "\n",
            "[[0.9975943  0.00136221 0.00104338]] 0\n",
            "\n",
            "[[0.9292684  0.06835053 0.00238107]] 0\n",
            "\n",
            "[[0.95527315 0.04316957 0.00155733]] 0\n",
            "\n",
            "[[0.9737781  0.02084633 0.00537547]] 0\n",
            "\n",
            "[[0.3366834  0.00738402 0.6559326 ]] 2\n",
            "\n",
            "[[0.99066013 0.00832519 0.00101474]] 0\n",
            "\n",
            "[[0.99744886 0.0015468  0.00100428]] 0\n",
            "\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "!Error To Resize of 20\n",
            "[[0.99735546 0.00117169 0.00147288]] 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}